%% set path correctly

addpath(genpath('C:\Users\Joris\Documents\MATLAB'));  % CODE TO ADD ALL SUBFOLDERS OF MATLAB-FOLDER TO PATH

%%
sewa_path = 'C:\Users\Joris\Documents\MATLAB\';       % this must be your database folder  

% READ IN MFCC's of training data *********************************************
%%************************************************************************

% Import data from text file.
% Script for importing data from the following text file:
%
%    C:\Users\Joris\Documents\MATLAB\audio_features_mfcc\Train_DE_01.csv
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

for k = 1 : 34 
% Initialize variables.
if k < 10
  filename = sprintf('%s%s%d%s', sewa_path,'audio_features_mfcc\Train_DE_0',k,'.csv');
else
  filename = sprintf('%s%s%d%s', sewa_path,'audio_features_mfcc\Train_DE_',k,'.csv');
end

delimiter = ';';
startRow = 2;

%% Format for each line of text:
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
%	column6: double (%f)
%   column7: double (%f)
%	column8: double (%f)
%   column9: double (%f)
%	column10: double (%f)
%   column11: double (%f)
%	column12: double (%f)
%   column13: double (%f)
%	column14: double (%f)
%   column15: double (%f)
% For more information, see the TEXTSCAN documentation.
formatSpec = '%*s%*s%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to the format.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string', 'EmptyValue', NaN, 'HeaderLines' ,startRow-1, 'ReturnOnError', false, 'EndOfLine', '\r\n');

%% Close the text file.
fclose(fileID);

%% Post processing for unimportable data.
% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.

%% Create output variable
if k == 1 
  Xtrain_raw = [dataArray{1:end-1}];
  rest = rem(length(Xtrain_raw),10);
  if rest ~= 0     % make sure length of Xtrain_raw is a multiple of 10 so the data lines up with the labels
    xtrarows = 10 - rest;
    for index1 = 1 : xtrarows
      Xtrain_raw = [ Xtrain_raw; Xtrain_raw(length(Xtrain_raw)-xtrarows+1,:) ] ;
    end
  end
else
  Xtrain_raw = [Xtrain_raw;dataArray{1:end-1}];
  rest = rem(length(Xtrain_raw),10);
  if rest ~= 0     % make sure length of Xtrain_raw is a multiple of 10 so the data lines up with the labels
    xtrarows = 10 - rest;
    for index1 = 1 : xtrarows
      Xtrain_raw = [ Xtrain_raw; Xtrain_raw(length(Xtrain_raw)-xtrarows+1,:) ] ;
    end
  end  
end
% last 3 seconds need to be removed, features are given every 10 ms so we
% need to remove the last 300 rows 
 Xtrain_raw =  Xtrain_raw(1:length(Xtrain_raw)-400 , :)  ;  % dropping last 400 rows = 4 seconds

%% Clear temporary variables
clearvars filename delimiter startRow formatSpec fileID dataArray ans k index1 rest xtrarows;

end % ALL DATA IS NOW STORED IN Xtrain_raw

% READ IN MFCC's of development data *****************************************
%*****************************************************************************

% Import data from text file.
% Script for importing data from the following text file:
%
%    C:\Users\Joris\Documents\MATLAB\audio_features_mfcc\Train_DE_01.csv
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2018/10/15 17:18:34

for k = 1 : 14 
%% Initialize variables.
if k < 10
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\audio_features_mfcc\Devel_DE_0',k,'.csv');
else
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\audio_features_mfcc\Devel_DE_',k,'.csv');
end

delimiter = ';';
startRow = 2;

%% Format for each line of text:
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
%	column6: double (%f)
%   column7: double (%f)
%	column8: double (%f)
%   column9: double (%f)
%	column10: double (%f)
%   column11: double (%f)
%	column12: double (%f)
%   column13: double (%f)
%	column14: double (%f)
%   column15: double (%f)
% For more information, see the TEXTSCAN documentation.
formatSpec = '%*s%*s%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%f%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to the format.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string', 'EmptyValue', NaN, 'HeaderLines' ,startRow-1, 'ReturnOnError', false, 'EndOfLine', '\r\n');

%% Close the text file.
fclose(fileID);

%% Post processing for unimportable data.
% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.

%% Create output variable
if k == 1 
  Xdevelop_raw = [dataArray{1:end-1}];
  rest = rem(length(Xdevelop_raw),10);
  if rest ~= 0     % make sure length of Xdevelop_raw is a multiple of 10 so the data lines up with the labels
    xtrarows = 10 - rest;
    for index1 = 1 : xtrarows
      Xdevelop_raw = [ Xdevelop_raw; Xdevelop_raw(length(Xdevelop_raw)-xtrarows+1,:) ] ;
    end
  end
else
  Xdevelop_raw = [Xdevelop_raw;dataArray{1:end-1}];
  rest = rem(length(Xdevelop_raw),10);
  if rest ~= 0     % make sure length of Xdevelop_raw is a multiple of 10 so the data lines up with the labels
    xtrarows = 10 - rest;
    for index1 = 1 : xtrarows
      Xdevelop_raw = [ Xdevelop_raw; Xdevelop_raw(length(Xdevelop_raw)-xtrarows+1,:) ] ;
    end
  end  
end
% last 3 seconds need to be removed, features are given every 10 ms so we
% need to remove the last 300 rows 
 Xdevelop_raw =  Xdevelop_raw(1:length(Xdevelop_raw)-400 , :)  ;  % dropping last 400 rows = 4 seconds

%% Clear temporary variables
clearvars filename delimiter startRow formatSpec fileID dataArray ans k index1 rest xtrarows;

end % ALL DATA IS NOW STORED IN Xdevelop_raw


% READ IN LABELS OF TRAINING DATA ***************************************
%************************************************************************

% Import data from text file.
% Script for importing data from the following text file:
%
%    C:\Users\Joris\Documents\MATLAB\labels\Train_DE_01.csv
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2018/10/17 20:20:11

% Initialize variables.
% filename = 'C:\Users\Joris\Documents\MATLAB\labels\Train_DE_01.csv';
for k = 1 : 34 
%% Initialize variables.
if k < 10
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\labels\Train_DE_0',k,'.csv');
else
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\labels\Train_DE_',k,'.csv');
end

delimiter = ';';

%% Format for each line of text:
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
% For more information, see the TEXTSCAN documentation.
formatSpec = '%*s%*s%f%f%f%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to the format.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string',  'ReturnOnError', false);

%% Close the text file.
fclose(fileID);

%% Post processing for unimportable data.
% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.

%% Create output variable
% TrainDE01 = [dataArray{1:end-1}];
if k == 1 
  Ytrain = [dataArray{1:end-1}];
else
  Ytrain = [Ytrain;dataArray{1:end-1}];    
end
% first 3 seconds of Ytrain need to be removed, this corresponds to 30 rows since annotation is every 100 ms 
  Ytrain = Ytrain(41:length(Ytrain), :) ; %first 40 rows are dropped = 40 seconds
%% Clear temporary variables
clearvars filename delimiter formatSpec fileID dataArray ans k;
end

% READ IN DEVELOPMENT LABELS ***********************************************
% Import data from text file.
% Script for importing data from the following text file:
%
%    C:\Users\Joris\Documents\MATLAB\labels\Train_DE_01.csv
%
% To extend the code to different selected data or a different text file,
% generate a function instead of a script.

% Auto-generated by MATLAB on 2018/10/17 20:20:11

% Initialize variables.
% filename = 'C:\Users\Joris\Documents\MATLAB\labels\Train_DE_01.csv';
for k = 1 : 14 
%% Initialize variables.
if k < 10
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\labels\Devel_DE_0',k,'.csv');
else
  filename = sprintf('%s%d%s','C:\Users\Joris\Documents\MATLAB\labels\Devel_DE_',k,'.csv');
end

delimiter = ';';

%% Format for each line of text:
%   column3: double (%f)
%	column4: double (%f)
%   column5: double (%f)
%   For more information, see the TEXTSCAN documentation.
formatSpec = '%*s%*s%f%f%f%[^\n\r]';

%% Open the text file.
fileID = fopen(filename,'r');

%% Read columns of data according to the format.
% This call is based on the structure of the file used to generate this
% code. If an error occurs for a different file, try regenerating the code
% from the Import Tool.
dataArray = textscan(fileID, formatSpec, 'Delimiter', delimiter, 'TextType', 'string',  'ReturnOnError', false);

%% Close the text file.
fclose(fileID);

%% Post processing for unimportable data.
% No unimportable data rules were applied during the import, so no post
% processing code is included. To generate code which works for
% unimportable data, select unimportable cells in a file and regenerate the
% script.

%% Create output variable
% TrainDE01 = [dataArray{1:end-1}];
if k == 1 
  Ydevelop = [dataArray{1:end-1}];
else
  Ydevelop = [Ydevelop;dataArray{1:end-1}];    
end
% first 3 seconds of Ydevelop need to be removed, this corresponds to 30 rows since annotation is every 100 ms 
  Ydevelop = Ydevelop(41:length(Ydevelop), :) ; %first 40 rows are dropped = 40 seconds
%% Clear temporary variables
clearvars filename delimiter formatSpec fileID dataArray ans k;
end

%% Change length of Xtrain_raw to same length as Ytrain
Xtrain = zeros(length(Ytrain),10*39); 
for index2 = 1 : length(Xtrain)
  for index3 = 1 : 10
    Xtrain(index2, index3*39-38:index3*39) = Xtrain_raw( (index2-1)*10+index3 ,:);
  end    
end
clearvars index2 index3;

% Change length of Xdevelop_raw to same length as Y1develop
Xdevelop = zeros(length(Ydevelop),10*39); 
for index2 = 1 : length(Xdevelop)
  for index3 = 1 : 10
    Xdevelop(index2, index3*39-38:index3*39) = Xdevelop_raw( (index2-1)*10+index3 ,:);
  end    
end
clearvars index2 index3;

% split Ytrain into 3 different 1-by-N matrices
Ytrain1 = Ytrain(:,1);
Ytrain2 = Ytrain(:,2);
Ytrain3 = Ytrain(:,3);

% split Ydevelop into 3 different 1-by-N matrices
Ydevelop1 = Ydevelop(:,1);
Ydevelop2 = Ydevelop(:,2);
Ydevelop3 = Ydevelop(:,3);


% DELAY COMPENSATION  (ALREADY IMPLEMENTED ABOVE) 
% 4 first seconds of labels where dropped and last 4 seconds of features were dropped! 
%******************************************************************************************
% FROM LITERATURE ON SEWA: "The optimal delay compensation, estimated using multimodal
% features, was found to be 4s for arousal and 2s for valence."
%
% "... temporal shifts were applied for each file in the training set in order to realign the features
% with the ground truth. The frame shift was achieved by dropping first N ground truth scores and last 
% N input feature frames.."
%******************************************************************************************

%% RANDOMIZATION AND NORMALIZATION
% From here on all pre-processing is done, delay compensation is performed and
% the sizes of X and Ytrain are matched 

% also randomize the sequence of the training data and the labels (arousal only)
sel = randperm(size(Xtrain,1));
Xtrain = Xtrain(sel,:);
Ytrain1 = Ytrain1(sel,:);
Ytrain2 = Ytrain2(sel,:);
clearvars sel; 

% normalize the features with respect to training mean and std
stdX = std(Xtrain);       
meanX = mean(Xtrain);

for index4 = 1 : 390
  Xtrain(:,index4) = (Xtrain(:,index4)-meanX(1,index4))/stdX(1,index4);    
  Xdevelop(:,index4) = (Xdevelop(:,index4)-meanX(1,index4))/stdX(1,index4); 
end

% normalize arousal labels

stdY1 = std(Ytrain1);
meanY1 = mean(Ytrain1);

Ytrain1 = (Ytrain1-meanY1)/stdY1;
Ydevelop1 = (Ydevelop1-meanY1)/stdY1;

% normalize valence labels

stdY2 = std(Ytrain2);
meanY2 = mean(Ytrain2);

Ytrain2 = (Ytrain2-meanY2)/stdY2;
Ydevelop2 = (Ydevelop2-meanY2)/stdY2;

clearvars index4 stdX meanX stdY1 meanY1 stdY2 meanY2 Xdevelop_raw Xtrain_raw;

%% Fixed size LS-SVM part starts here %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The fixed size LS-SVM is based on two ideas (see also Section 2.4): the first is to exploit the
% primal-dual formulations of the LS-SVM in view of a Nystr¨om approximation 

% The second one is to do active support vector selection (here based on entropy criteria). The

%% Determine the best size of the subset %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Optimal values for the kernel parameters and the capacity of the fixed size LS-SVM can be
% obtained using a simple Monte Carlo experiment. For different kernel parameters and capacities
% (number of chosen support vectors), the performance on random subsets of support vectors are
% evaluated. The means of the performances are minimized by an exhaustive search
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

target = 'valence';   % set target to be either valence or arousal
if(target ==  'arousal')
    y_train = Ytrain1;
    y_dev = Ydevelop1;
else
     if (target == 'valence')
        y_train = Ytrain2;
        y_dev = Ydevelop2;
     else
        printf("invalid target was specified") 
     end
    
end

caps = [50 100 200];                                  % grid search on size of subset 
sig2s = [0.01 1 100 250 500 1000 3000 10000 20000];   % and sigma²    
windows = [3 10 30 100];                              % smoothing windows with a different length are applied to the output
nb = 4;

performances_without_filter = zeros(length(caps),length(sig2s));   % development performance 
performances_without_filter_scaled = zeros(length(caps),length(sig2s));
max_performances_1 = zeros(length(caps),length(sig2s));
max_performances_2 = zeros(length(caps),length(sig2s));
max_performances_3 = zeros(length(caps),length(sig2s));
max_performances_4 = zeros(length(caps),length(sig2s));
performances = zeros(nb, 5);
performances_scaled = zeros(nb, 5);

max_performances_train = zeros(length(caps),length(sig2s));        % training performance
max_performances_train_scaled = zeros(length(caps),length(sig2s));
performances_train = zeros(nb, 1);
performances_train_scaled = zeros(nb, 1);

for i=1:length(caps)
    for j=1:length(sig2s)
     for t = 1:nb
       fprintf('iteration outer-loop: %d/%d, middle loop: %d/%d, inner loop: %d/%d \n',i,length(caps),j,length(sig2s),t,nb);
       sel = randperm(size(Xtrain,1));
       svX = Xtrain(sel(1:caps(i)),:);
       svY = Ytrain1(sel(1:caps(i)),1);
       features = AFEm(svX,'RBF_kernel',sig2s(j), Xtrain);       
       [Cl3, gam_opt] = bay_rr(features,Ytrain1,1,3);   
       [W,b] = ridgeregress(features, Ytrain1, gam_opt);
       features = AFEm(svX,'RBF_kernel',sig2s(j), svX);
       Yh_train = features*W+b;
       Yh_train_scaled = (Yh_train - mean(Yh_train))/nanstd(Yh_train);
       features = AFEm(svX,'RBF_kernel',sig2s(j), Xdevelop);
       Yh = features*W+b;
       Yh_scaled = (Yh - mean(Yh))/nanstd(Yh) ;             % rescaled prediction   ********************************       
       performances(t, 5) =  CCC_calc(Yh, Ydevelop1);       % performance without window
       performances_scaled(t, 5) = CCC_calc(Yh_scaled, Ydevelop1);
       performances_train(t, 1) =  CCC_calc(Yh_train, svY); % training performance
       performances_train_scaled(t, 1) =  CCC_calc(Yh_train_scaled, svY);
       for k = 1 : 4
       Yh_smoothed = smooth_joris(Yh,windows(k));
       Yh_smoothed = (Yh_smoothed - nanmean(Yh_smoothed))/nanstd(Yh_smoothed);
       performances(t,k) = CCC_calc(Yh_smoothed,Ydevelop1);              
       end
     end
     max_performances_1(i,j) = mean(performances(:,1));                  % development performances 
     max_performances_2(i,j) = mean(performances(:,2));
     max_performances_3(i,j) = mean(performances(:,3));
     max_performances_4(i,j) = mean(performances(:,4));
     performances_without_filter(i,j) = mean(performances(:,5));
     performances_without_filter_scaled(i,j) = mean(performances_scaled(:,5));
     max_performances_train(i,j) = mean(performances_train(:,1));             % training performance 
     max_performances_train_scaled(i,j) = mean(performances_train_scaled(:,1));
   end
end
fprintf('finished grid search on capacity and sigma \n')

%% save performances

csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\caps.csv', caps);  % save grid parameters as well 
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\sig2s.csv', sig2s);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\windows.csv', windows);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc0.csv', performances_without_filter_scaled); 
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc1.csv', max_performances_1); 
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc2.csv', max_performances_2); 
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc3.csv', max_performances_3); 
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc4.csv', max_performances_4);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\train_ccc.csv', max_performances_train);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\train_ccc_scaled.csv', max_performances_train_scaled);

%% train once more with the best parameters so the corresponding predcitions can be plotted
 
 features = AFEm(svX,'RBF_kernel',sig2s(j), Xtrain);       
 [Cl3, gam_opt] = bay_rr(features,Ytrain1,1,3);   
 [W,b] = ridgeregress(features, Ytrain1, gam_opt);
 features = AFEm(svX,'RBF_kernel',sig2s(j), svX);
 Yh_train = features*W+b;
 features = AFEm(svX,'RBF_kernel',sig2s(j), Xdevelop);
 Yh = features*W+b;


%% plot CCC's
figure; 
plot(sig2s(1:7), max_performances_train_scaled(1, 1:7), sig2s(1:7), max_performances_4(1, 1:7));
title('Training and Development CCC as a function of sigma²');
xlabel('sigma²') 
ylabel('Concordance Correlation Coëfficient') 
legend('Training set', 'Development set', 'Location', 'SouthEast');

%% plot predictions
xas = 1:length(Yh);

figure;
plot(xas, Ydevelop1, xas, Yh);
title('Prediction on Development data without scaling or smoothing');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');

figure;
plot(xas, Ydevelop1, xas, Yh_scaled);
title('Prediction on Development data with scaling');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');

figure;
plot(xas, Ydevelop1, xas, Yh_smoothed);
title('Prediction on Development data with scaling and smoothing');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% select the best subset of X_train by maximizing quadratic Renyi entropy         %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% initiate values
Nc=100;                        % this is the number of samples in the subset

subset_indices = zeros(Nc,1);  % create column vector
for p = 1 : Nc
   subset_indices(p,1) = p ;   % initial indices are 1 -> 200 
end 

kernel = 'RBF_kernel';
sigma2= 10000;
crit_old=-inf;
Xs=Xtrain(1:Nc,:);
Ys=Ytrain1(1:Nc,:);
disp(' The optimal reduced set is constructed iteratively: ');
%
% iterate over data
%
tv = 1;
tel2 = 0;
for tel=1:length(Xtrain)  
    
  if rem(tel,100) == 0 || tel2 == 0              % printf to follow progress during execution
    fprintf('iteration #%d/%d just started \n',tel2*100, length(Xtrain));
    tel2 = tel2+1 ;
  end
  
  % new candidate set
  Xsp=Xs; Ysp=Ys;
  % S=ceil(length(Xtrain)*rand(1));
  Sc=ceil(Nc*rand(1));
  Xs(Sc,:) = Xtrain(tel,:);
  Ys(Sc,:) = Ytrain1(tel);  
  %
  % automaticly extract features and compute entropy
  %
  crit = kentropy(Xs,kernel, sigma2);
  
  if crit <= crit_old
    crit = crit_old;
    Xs=Xsp;
    Ys=Ysp;  
  else
    crit_old = crit;
    subset_indices(Sc) = tel; 
    
  end  
end
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%    TRY AND DETERMINE THE BEST VALUES FOR sigma² and gamma    %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

gammarray = [0.0000001]; % either we use bay_rr() to determine gamma, or we do a grid search on this paramater
sigmarray = [0.01 10 100 200 300 400 500 1000 2000 3000];
opt_gams = [1:length(sigmarray)];
windows = [3 10 30 100];            % 4 different smoothing windows are applied to the predictions

performances_1_subset = zeros(length(gammarray),length(sigmarray));   % 1 matrix to save performance for each 
performances_2_subset = zeros(length(gammarray),length(sigmarray));   % smoothing window applied 
performances_3_subset = zeros(length(gammarray),length(sigmarray)); 
performances_4_subset = zeros(length(gammarray),length(sigmarray)); 
perf_without_filter_subset = zeros(length(gammarray),length(sigmarray)); % 1 matrix to save performance without smoothing
performances_subset = [0 0 0 0];          % temp array to transfer 4 results of the smoothing funtion

performances_1_scaled_smoothed = zeros(length(gammarray),length(sigmarray)); 
performances_2_scaled_smoothed = zeros(length(gammarray),length(sigmarray)); 
performances_3_scaled_smoothed = zeros(length(gammarray),length(sigmarray)); 
performances_4_scaled_smoothed = zeros(length(gammarray),length(sigmarray));
performances_scaled_smoothed = [0 0 0 0];

training_CCC = zeros(length(gammarray), length(sigmarray));
training_CCC_scaled = zeros(length(gammarray), length(sigmarray));

for i = 1 : length(gammarray)   % loop over all gamma canidate-values
  for j = 1 : length(sigmarray) % loop over all sigma candidate-values    
       fprintf('outer-loop: %d/%d , inner-loop: %d/%d \n',i ,length(gammarray), j, length(sigmarray));
       features = AFEm(Xs,'RBF_kernel',sigmarray(j), Xtrain);       
       [Cl3, gam_opt] = bay_rr(features,Ytrain1,1,3); 
       opt_gams(j) = gam_opt;
       [W,b] = ridgeregress(features, Ytrain1, gam_opt);
       features = AFEm(Xs,'RBF_kernel',sigmarray(j), Xs);              % save training data performance
       Yh_train = features*W+b;
       Yh_train_scaled = (Yh_train - mean(Yh_train))/nanstd(Yh_train);
       features = AFEm(Xs,'RBF_kernel',sigmarray(j), Xdevelop);        % map devel data to feature space 
       Yh = features*W+b;
       Yh_scaled = (Yh - nanmean(Yh))/nanstd(Yh);                          % rescaling
       perf_without_filter_subset(i,j) = CCC_calc(Yh_scaled, Ydevelop1);   % save devel CCC without smoothing
       for k = 1 : 4
         Yh_smoothed = smooth_joris(Yh,windows(k));                        % smoothing
         Yh_smoothed = (Yh_smoothed - nanmean(Yh_smoothed))/nanstd(Yh_smoothed); % scaling 
         performances_subset(k) = CCC_calc(Yh_smoothed,Ydevelop1);         % save development CCC
         
         Yh_scaled_smoothed = smooth_joris(Yh_scaled, windows(k));         % smoothing
         performances_scaled_smoothed(k) = CCC_calc(Yh_scaled_smoothed,Ydevelop1);          
       end    
     performances_1_subset(i,j) = performances_subset(1);
     performances_2_subset(i,j) = performances_subset(2);
     performances_3_subset(i,j) = performances_subset(3);
     performances_4_subset(i,j) = performances_subset(4);     
     performances_1_scaled_smoothed(i,j) = performances_scaled_smoothed(1);
     performances_2_scaled_smoothed(i,j) = performances_scaled_smoothed(2);     
     performances_3_scaled_smoothed(i,j) = performances_scaled_smoothed(3);
     performances_4_scaled_smoothed(i,j) = performances_scaled_smoothed(4);     
     training_CCC(i,j) = CCC_calc(Yh_train, Ys);
     training_CCC_scaled(i,j) = CCC_calc(Yh_train_scaled, Ys);
  end
end

%% save grid parameters
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\sigmarray.csv', sigmarray);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\gammarray.csv', gammarray);

csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\develop_ccc4.csv', performances_4_subset);
csvwrite('C:\Users\Joris\Documents\MATLAB\perf_sewa\valence\train_ccc_scaled.csv', training_CCC_scaled);


%% plotting
% plot CCC's
figure; 
plot(sigmarray, training_CCC_scaled, sigmarray, performances_4_subset);
title('Training and Development CCC as a function of sigma²');
xlabel('sigma²') 
ylabel('Concordance Correlation Coëfficient') 
legend('Training set', 'Development set', 'Location', 'SouthEast');

%% plot predictions
xas = 1:length(Yh);
figure;
plot(xas, Ydevelop1, xas, Yh);
title('Prediction on Development data without scaling or smoothing');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');

figure;
plot(xas, Ydevelop1, xas, Yh_scaled);
title('Prediction on Development data with scaling');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');

figure;
plot(xas, Ydevelop1, xas, Yh_smoothed);
title('Prediction on Development data with scaling and smoothing');
xlabel('sample number') 
ylabel('Arousal') 
legend('Ground Truth', 'Prediction', 'Location', 'SouthEast');
hold off;


%% Multi Dimensional Scaling
%  1) take random sample of subset, size = 10k samples ?
sze = 10000;
getter_indx = randperm(sze);
getter_indx = getter_indx' ;
getter_indx = [subset_indices(:) ; getter_indx];
Xmds = Xtrain(getter_indx, : );
%%  2) MDS on random samples + 200 selected SV's
% Create a dissimilarity matrix.
dissimilarities = pdist(Xmds,'euclidean');
%% square form
dissimilarities = squareform(dissimilarities);
%%
[Xreduced,e] = cmdscale(dissimilarities, 2);
%
%% 3) Plot random samples in blue and SV's in red 
rand_idx = randperm(10100);
figure;
plot(Xreduced(101:10100,1),Xreduced(101:10100,2),'b.', Xreduced(1:100,1),Xreduced(1:100,2),'ro', Xreduced(rand_idx(1:100),1),Xreduced(rand_idx(1:100),2),'go');
title('Plot of input data after using multidimensional scaling to bring the input dimension down to 2');
legend('Large random sample of input data', 'Actively selected subset', 'Random sample of input data with same size as subset' , 'Location', 'SouthEast');

